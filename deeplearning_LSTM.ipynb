{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,Dropout,Input\n",
    "from keras.layers import Embedding,LSTM,GlobalMaxPooling1D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "twit = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "twit_df = twit.drop(columns = ['id','keyword','location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1             Forest fire near La Ronge Sask. Canada       1\n",
       "2  All residents asked to 'shelter in place' are ...       1\n",
       "3  13,000 people receive #wildfires evacuation or...       1\n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(twit_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326\n"
     ]
    }
   ],
   "source": [
    "print(len(nlp.Defaults.stop_words))\n",
    "stopwords = (nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S\\s+')\n",
    "    return url.sub(r'',text)\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text) # no emoji\n",
    "\n",
    "def remove_punct(text):\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    return text\n",
    "    \n",
    "def stop_words(text):\n",
    "    text = \" \".join(word for word in text.split() if word not in stopwords)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    our deeds are the reason of this earthquake ma...\n",
       "1                forest fire near la ronge sask canada\n",
       "2    all residents asked to shelter in place are be...\n",
       "3     people receive wildfires evacuation orders in...\n",
       "4    just got sent this photo from ruby alaska as s...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twit_df['text'] = twit_df['text'].apply(remove_URL)\n",
    "twit_df['text'] = twit_df['text'].apply(remove_emoji)\n",
    "twit_df['text'] = twit_df['text'].map(lambda x: remove_punct(x))\n",
    "twit_df['text'] = twit_df['text'].map(lambda x: x.lower())\n",
    "#twit_df['text'] = twit_df['text'].apply(stop_words)\n",
    "\n",
    "twit_df['text'][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = twit_df['text']\n",
    "y = twit_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size = 0.33,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5836    photo postapocalypticflimflam prodding around ...\n",
      "30                                                the end\n",
      "1879                man crush everyday   cristianinspire \n",
      "6852    ptsdchat yes i feel the root of that is shame ...\n",
      "2673    autoames everyone hoped we would join isis and...\n",
      "Name: text, dtype: object\n",
      "(5100,)\n",
      "\n",
      "\n",
      "\n",
      "5836    0\n",
      "30      0\n",
      "1879    0\n",
      "6852    1\n",
      "2673    0\n",
      "Name: target, dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "2644    so you have a new weapon that can cause unimag...\n",
      "2227    the famping things i do for gishwhes just got ...\n",
      "5448    dt georgegalloway rt gallowaymayor ûïthe col ...\n",
      "132     aftershock back to school kick off was great i...\n",
      "6845    in response to trauma children of addicts deve...\n",
      "Name: text, dtype: object\n",
      "(2513,)\n",
      "\n",
      "\n",
      "\n",
      "2644    1\n",
      "2227    0\n",
      "5448    1\n",
      "132     0\n",
      "6845    0\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.head())\n",
    "print(X_train.shape)\n",
    "print('\\n\\n')\n",
    "\n",
    "print(y_train.head())\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "print(X_val.head())\n",
    "print(X_val.shape)\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "print(y_val.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 20000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[249, 4991, 4992, 332, 1, 657]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13375"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx = tokenizer.word_index\n",
    "\n",
    "print(X_train_seq[0])\n",
    "v= len(word2idx)\n",
    "v\n",
    "#print(X_val_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize input length by padding and trucating\n",
    "\n",
    "X_train_data = pad_sequences(X_train_seq)\n",
    "\n",
    "T = X_train_data.shape[1]\n",
    "\n",
    "X_val_data= pad_sequences(X_val_seq,maxlen=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2513, 31)\n"
     ]
    }
   ],
   "source": [
    "print(X_val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "D = 20\n",
    "M=15\n",
    "\n",
    "\n",
    "i = Input(shape=(T,))\n",
    "x = Embedding(v+1,D)(i)\n",
    "x = LSTM(M,return_sequences=True)(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(1,activation = 'sigmoid')(x)\n",
    "\n",
    "model = Model(i,x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 31)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 31, 20)            267520    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 31, 15)            2160      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 269,696\n",
      "Trainable params: 269,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'model_output/dense'\n",
    "\n",
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\"/weights.{epoch:02d}.hdf5\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cbatl\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5100 samples, validate on 2513 samples\n",
      "Epoch 1/10\n",
      "5100/5100 [==============================] - ETA: 2:07 - loss: 0.6919 - accuracy: 0.56 - ETA: 44s - loss: 0.6919 - accuracy: 0.5521 - ETA: 23s - loss: 0.6937 - accuracy: 0.500 - ETA: 16s - loss: 0.6921 - accuracy: 0.541 - ETA: 12s - loss: 0.6916 - accuracy: 0.546 - ETA: 10s - loss: 0.6915 - accuracy: 0.543 - ETA: 9s - loss: 0.6910 - accuracy: 0.546 - ETA: 8s - loss: 0.6912 - accuracy: 0.54 - ETA: 7s - loss: 0.6905 - accuracy: 0.54 - ETA: 6s - loss: 0.6896 - accuracy: 0.55 - ETA: 6s - loss: 0.6895 - accuracy: 0.55 - ETA: 5s - loss: 0.6898 - accuracy: 0.55 - ETA: 5s - loss: 0.6892 - accuracy: 0.55 - ETA: 5s - loss: 0.6896 - accuracy: 0.54 - ETA: 4s - loss: 0.6888 - accuracy: 0.55 - ETA: 4s - loss: 0.6886 - accuracy: 0.55 - ETA: 4s - loss: 0.6875 - accuracy: 0.55 - ETA: 4s - loss: 0.6879 - accuracy: 0.55 - ETA: 3s - loss: 0.6878 - accuracy: 0.55 - ETA: 3s - loss: 0.6876 - accuracy: 0.55 - ETA: 3s - loss: 0.6880 - accuracy: 0.54 - ETA: 3s - loss: 0.6870 - accuracy: 0.55 - ETA: 3s - loss: 0.6873 - accuracy: 0.54 - ETA: 3s - loss: 0.6865 - accuracy: 0.55 - ETA: 2s - loss: 0.6862 - accuracy: 0.55 - ETA: 2s - loss: 0.6856 - accuracy: 0.55 - ETA: 2s - loss: 0.6854 - accuracy: 0.55 - ETA: 2s - loss: 0.6837 - accuracy: 0.56 - ETA: 2s - loss: 0.6832 - accuracy: 0.56 - ETA: 2s - loss: 0.6823 - accuracy: 0.56 - ETA: 2s - loss: 0.6821 - accuracy: 0.56 - ETA: 2s - loss: 0.6820 - accuracy: 0.56 - ETA: 1s - loss: 0.6815 - accuracy: 0.55 - ETA: 1s - loss: 0.6809 - accuracy: 0.55 - ETA: 1s - loss: 0.6794 - accuracy: 0.56 - ETA: 1s - loss: 0.6781 - accuracy: 0.56 - ETA: 1s - loss: 0.6770 - accuracy: 0.56 - ETA: 1s - loss: 0.6766 - accuracy: 0.56 - ETA: 1s - loss: 0.6761 - accuracy: 0.56 - ETA: 1s - loss: 0.6746 - accuracy: 0.56 - ETA: 1s - loss: 0.6740 - accuracy: 0.56 - ETA: 1s - loss: 0.6724 - accuracy: 0.57 - ETA: 0s - loss: 0.6703 - accuracy: 0.57 - ETA: 0s - loss: 0.6700 - accuracy: 0.57 - ETA: 0s - loss: 0.6680 - accuracy: 0.57 - ETA: 0s - loss: 0.6666 - accuracy: 0.58 - ETA: 0s - loss: 0.6651 - accuracy: 0.58 - ETA: 0s - loss: 0.6644 - accuracy: 0.58 - ETA: 0s - loss: 0.6626 - accuracy: 0.59 - ETA: 0s - loss: 0.6605 - accuracy: 0.59 - ETA: 0s - loss: 0.6593 - accuracy: 0.59 - ETA: 0s - loss: 0.6580 - accuracy: 0.60 - ETA: 0s - loss: 0.6551 - accuracy: 0.60 - ETA: 0s - loss: 0.6536 - accuracy: 0.60 - 5s 916us/step - loss: 0.6527 - accuracy: 0.6104 - val_loss: 0.5446 - val_accuracy: 0.7803\n",
      "Epoch 2/10\n",
      "5100/5100 [==============================] - ETA: 4s - loss: 0.5036 - accuracy: 0.78 - ETA: 4s - loss: 0.5338 - accuracy: 0.76 - ETA: 4s - loss: 0.4935 - accuracy: 0.80 - ETA: 4s - loss: 0.4952 - accuracy: 0.80 - ETA: 3s - loss: 0.4740 - accuracy: 0.83 - ETA: 3s - loss: 0.4718 - accuracy: 0.83 - ETA: 3s - loss: 0.4743 - accuracy: 0.82 - ETA: 3s - loss: 0.4665 - accuracy: 0.84 - ETA: 3s - loss: 0.4658 - accuracy: 0.83 - ETA: 3s - loss: 0.4650 - accuracy: 0.83 - ETA: 3s - loss: 0.4650 - accuracy: 0.82 - ETA: 3s - loss: 0.4659 - accuracy: 0.82 - ETA: 3s - loss: 0.4678 - accuracy: 0.82 - ETA: 3s - loss: 0.4602 - accuracy: 0.82 - ETA: 3s - loss: 0.4588 - accuracy: 0.82 - ETA: 3s - loss: 0.4648 - accuracy: 0.82 - ETA: 2s - loss: 0.4592 - accuracy: 0.82 - ETA: 2s - loss: 0.4591 - accuracy: 0.82 - ETA: 2s - loss: 0.4601 - accuracy: 0.82 - ETA: 2s - loss: 0.4605 - accuracy: 0.82 - ETA: 2s - loss: 0.4571 - accuracy: 0.82 - ETA: 2s - loss: 0.4557 - accuracy: 0.82 - ETA: 2s - loss: 0.4558 - accuracy: 0.82 - ETA: 2s - loss: 0.4561 - accuracy: 0.82 - ETA: 2s - loss: 0.4556 - accuracy: 0.82 - ETA: 2s - loss: 0.4558 - accuracy: 0.82 - ETA: 2s - loss: 0.4554 - accuracy: 0.82 - ETA: 2s - loss: 0.4548 - accuracy: 0.82 - ETA: 2s - loss: 0.4566 - accuracy: 0.82 - ETA: 2s - loss: 0.4542 - accuracy: 0.82 - ETA: 2s - loss: 0.4557 - accuracy: 0.82 - ETA: 1s - loss: 0.4564 - accuracy: 0.82 - ETA: 1s - loss: 0.4543 - accuracy: 0.82 - ETA: 1s - loss: 0.4536 - accuracy: 0.82 - ETA: 1s - loss: 0.4525 - accuracy: 0.82 - ETA: 1s - loss: 0.4534 - accuracy: 0.82 - ETA: 1s - loss: 0.4527 - accuracy: 0.82 - ETA: 1s - loss: 0.4520 - accuracy: 0.82 - ETA: 1s - loss: 0.4508 - accuracy: 0.82 - ETA: 1s - loss: 0.4511 - accuracy: 0.82 - ETA: 1s - loss: 0.4520 - accuracy: 0.82 - ETA: 1s - loss: 0.4506 - accuracy: 0.82 - ETA: 1s - loss: 0.4487 - accuracy: 0.82 - ETA: 1s - loss: 0.4501 - accuracy: 0.82 - ETA: 1s - loss: 0.4483 - accuracy: 0.82 - ETA: 1s - loss: 0.4466 - accuracy: 0.82 - ETA: 1s - loss: 0.4461 - accuracy: 0.82 - ETA: 1s - loss: 0.4443 - accuracy: 0.82 - ETA: 0s - loss: 0.4430 - accuracy: 0.82 - ETA: 0s - loss: 0.4426 - accuracy: 0.82 - ETA: 0s - loss: 0.4403 - accuracy: 0.83 - ETA: 0s - loss: 0.4391 - accuracy: 0.83 - ETA: 0s - loss: 0.4376 - accuracy: 0.83 - ETA: 0s - loss: 0.4364 - accuracy: 0.83 - ETA: 0s - loss: 0.4346 - accuracy: 0.83 - ETA: 0s - loss: 0.4328 - accuracy: 0.83 - ETA: 0s - loss: 0.4323 - accuracy: 0.83 - ETA: 0s - loss: 0.4321 - accuracy: 0.83 - ETA: 0s - loss: 0.4327 - accuracy: 0.83 - ETA: 0s - loss: 0.4330 - accuracy: 0.83 - ETA: 0s - loss: 0.4322 - accuracy: 0.83 - ETA: 0s - loss: 0.4324 - accuracy: 0.83 - ETA: 0s - loss: 0.4317 - accuracy: 0.83 - 4s 823us/step - loss: 0.4311 - accuracy: 0.8337 - val_loss: 0.4598 - val_accuracy: 0.8138\n",
      "Epoch 3/10\n",
      "5100/5100 [==============================] - ETA: 4s - loss: 0.3603 - accuracy: 0.84 - ETA: 4s - loss: 0.3670 - accuracy: 0.88 - ETA: 4s - loss: 0.3609 - accuracy: 0.88 - ETA: 3s - loss: 0.3262 - accuracy: 0.90 - ETA: 4s - loss: 0.3135 - accuracy: 0.90 - ETA: 3s - loss: 0.3088 - accuracy: 0.90 - ETA: 3s - loss: 0.3118 - accuracy: 0.90 - ETA: 3s - loss: 0.3127 - accuracy: 0.90 - ETA: 3s - loss: 0.3032 - accuracy: 0.91 - ETA: 3s - loss: 0.2965 - accuracy: 0.91 - ETA: 3s - loss: 0.2899 - accuracy: 0.91 - ETA: 3s - loss: 0.2879 - accuracy: 0.91 - ETA: 3s - loss: 0.2873 - accuracy: 0.91 - ETA: 3s - loss: 0.2837 - accuracy: 0.91 - ETA: 3s - loss: 0.2855 - accuracy: 0.91 - ETA: 2s - loss: 0.2839 - accuracy: 0.91 - ETA: 2s - loss: 0.2829 - accuracy: 0.91 - ETA: 2s - loss: 0.2851 - accuracy: 0.90 - ETA: 2s - loss: 0.2850 - accuracy: 0.91 - ETA: 2s - loss: 0.2853 - accuracy: 0.90 - ETA: 2s - loss: 0.2834 - accuracy: 0.91 - ETA: 2s - loss: 0.2830 - accuracy: 0.91 - ETA: 2s - loss: 0.2827 - accuracy: 0.90 - ETA: 2s - loss: 0.2816 - accuracy: 0.90 - ETA: 2s - loss: 0.2805 - accuracy: 0.90 - ETA: 2s - loss: 0.2809 - accuracy: 0.90 - ETA: 2s - loss: 0.2809 - accuracy: 0.90 - ETA: 2s - loss: 0.2786 - accuracy: 0.90 - ETA: 2s - loss: 0.2798 - accuracy: 0.90 - ETA: 2s - loss: 0.2807 - accuracy: 0.90 - ETA: 1s - loss: 0.2815 - accuracy: 0.90 - ETA: 1s - loss: 0.2797 - accuracy: 0.90 - ETA: 1s - loss: 0.2783 - accuracy: 0.90 - ETA: 1s - loss: 0.2784 - accuracy: 0.90 - ETA: 1s - loss: 0.2770 - accuracy: 0.91 - ETA: 1s - loss: 0.2767 - accuracy: 0.91 - ETA: 1s - loss: 0.2770 - accuracy: 0.91 - ETA: 1s - loss: 0.2773 - accuracy: 0.91 - ETA: 1s - loss: 0.2770 - accuracy: 0.91 - ETA: 1s - loss: 0.2762 - accuracy: 0.91 - ETA: 1s - loss: 0.2748 - accuracy: 0.91 - ETA: 1s - loss: 0.2742 - accuracy: 0.91 - ETA: 1s - loss: 0.2756 - accuracy: 0.91 - ETA: 1s - loss: 0.2765 - accuracy: 0.91 - ETA: 0s - loss: 0.2771 - accuracy: 0.90 - ETA: 0s - loss: 0.2751 - accuracy: 0.91 - ETA: 0s - loss: 0.2738 - accuracy: 0.91 - ETA: 0s - loss: 0.2732 - accuracy: 0.91 - ETA: 0s - loss: 0.2718 - accuracy: 0.91 - ETA: 0s - loss: 0.2727 - accuracy: 0.91 - ETA: 0s - loss: 0.2715 - accuracy: 0.91 - ETA: 0s - loss: 0.2702 - accuracy: 0.91 - ETA: 0s - loss: 0.2692 - accuracy: 0.91 - ETA: 0s - loss: 0.2690 - accuracy: 0.91 - ETA: 0s - loss: 0.2695 - accuracy: 0.91 - ETA: 0s - loss: 0.2703 - accuracy: 0.91 - ETA: 0s - loss: 0.2704 - accuracy: 0.91 - ETA: 0s - loss: 0.2718 - accuracy: 0.91 - ETA: 0s - loss: 0.2704 - accuracy: 0.91 - ETA: 0s - loss: 0.2696 - accuracy: 0.91 - 4s 795us/step - loss: 0.2695 - accuracy: 0.9120 - val_loss: 0.4859 - val_accuracy: 0.7907\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5100/5100 [==============================] - ETA: 4s - loss: 0.2382 - accuracy: 0.93 - ETA: 4s - loss: 0.2152 - accuracy: 0.93 - ETA: 4s - loss: 0.2379 - accuracy: 0.93 - ETA: 3s - loss: 0.2014 - accuracy: 0.94 - ETA: 3s - loss: 0.2013 - accuracy: 0.94 - ETA: 3s - loss: 0.1888 - accuracy: 0.95 - ETA: 3s - loss: 0.1848 - accuracy: 0.95 - ETA: 3s - loss: 0.1797 - accuracy: 0.95 - ETA: 3s - loss: 0.1821 - accuracy: 0.95 - ETA: 3s - loss: 0.1784 - accuracy: 0.95 - ETA: 3s - loss: 0.1875 - accuracy: 0.95 - ETA: 3s - loss: 0.1835 - accuracy: 0.95 - ETA: 2s - loss: 0.1870 - accuracy: 0.95 - ETA: 2s - loss: 0.1820 - accuracy: 0.95 - ETA: 2s - loss: 0.1809 - accuracy: 0.95 - ETA: 2s - loss: 0.1853 - accuracy: 0.95 - ETA: 2s - loss: 0.1823 - accuracy: 0.95 - ETA: 2s - loss: 0.1812 - accuracy: 0.95 - ETA: 2s - loss: 0.1826 - accuracy: 0.95 - ETA: 2s - loss: 0.1816 - accuracy: 0.95 - ETA: 2s - loss: 0.1828 - accuracy: 0.95 - ETA: 2s - loss: 0.1814 - accuracy: 0.95 - ETA: 2s - loss: 0.1800 - accuracy: 0.95 - ETA: 2s - loss: 0.1792 - accuracy: 0.95 - ETA: 2s - loss: 0.1804 - accuracy: 0.95 - ETA: 2s - loss: 0.1799 - accuracy: 0.95 - ETA: 2s - loss: 0.1773 - accuracy: 0.95 - ETA: 2s - loss: 0.1785 - accuracy: 0.95 - ETA: 2s - loss: 0.1805 - accuracy: 0.94 - ETA: 2s - loss: 0.1793 - accuracy: 0.95 - ETA: 2s - loss: 0.1781 - accuracy: 0.95 - ETA: 1s - loss: 0.1776 - accuracy: 0.95 - ETA: 1s - loss: 0.1771 - accuracy: 0.95 - ETA: 1s - loss: 0.1779 - accuracy: 0.95 - ETA: 1s - loss: 0.1767 - accuracy: 0.95 - ETA: 1s - loss: 0.1775 - accuracy: 0.95 - ETA: 1s - loss: 0.1759 - accuracy: 0.95 - ETA: 1s - loss: 0.1769 - accuracy: 0.95 - ETA: 1s - loss: 0.1769 - accuracy: 0.95 - ETA: 1s - loss: 0.1756 - accuracy: 0.95 - ETA: 1s - loss: 0.1768 - accuracy: 0.95 - ETA: 1s - loss: 0.1774 - accuracy: 0.95 - ETA: 1s - loss: 0.1761 - accuracy: 0.95 - ETA: 1s - loss: 0.1755 - accuracy: 0.95 - ETA: 1s - loss: 0.1744 - accuracy: 0.95 - ETA: 1s - loss: 0.1731 - accuracy: 0.95 - ETA: 1s - loss: 0.1727 - accuracy: 0.95 - ETA: 1s - loss: 0.1721 - accuracy: 0.95 - ETA: 0s - loss: 0.1728 - accuracy: 0.95 - ETA: 0s - loss: 0.1714 - accuracy: 0.95 - ETA: 0s - loss: 0.1709 - accuracy: 0.95 - ETA: 0s - loss: 0.1725 - accuracy: 0.95 - ETA: 0s - loss: 0.1718 - accuracy: 0.95 - ETA: 0s - loss: 0.1728 - accuracy: 0.95 - ETA: 0s - loss: 0.1749 - accuracy: 0.95 - ETA: 0s - loss: 0.1774 - accuracy: 0.94 - ETA: 0s - loss: 0.1801 - accuracy: 0.94 - ETA: 0s - loss: 0.1809 - accuracy: 0.94 - ETA: 0s - loss: 0.1807 - accuracy: 0.94 - ETA: 0s - loss: 0.1809 - accuracy: 0.94 - ETA: 0s - loss: 0.1826 - accuracy: 0.94 - ETA: 0s - loss: 0.1823 - accuracy: 0.94 - ETA: 0s - loss: 0.1827 - accuracy: 0.94 - 4s 822us/step - loss: 0.1826 - accuracy: 0.9475 - val_loss: 0.5573 - val_accuracy: 0.7553\n",
      "Epoch 5/10\n",
      "5100/5100 [==============================] - ETA: 4s - loss: 0.0901 - accuracy: 1.00 - ETA: 4s - loss: 0.1531 - accuracy: 0.97 - ETA: 4s - loss: 0.1374 - accuracy: 0.98 - ETA: 3s - loss: 0.1367 - accuracy: 0.97 - ETA: 3s - loss: 0.1538 - accuracy: 0.96 - ETA: 3s - loss: 0.1554 - accuracy: 0.96 - ETA: 3s - loss: 0.1527 - accuracy: 0.96 - ETA: 3s - loss: 0.1505 - accuracy: 0.96 - ETA: 3s - loss: 0.1436 - accuracy: 0.96 - ETA: 3s - loss: 0.1461 - accuracy: 0.96 - ETA: 3s - loss: 0.1458 - accuracy: 0.96 - ETA: 2s - loss: 0.1545 - accuracy: 0.95 - ETA: 2s - loss: 0.1536 - accuracy: 0.95 - ETA: 2s - loss: 0.1508 - accuracy: 0.95 - ETA: 2s - loss: 0.1463 - accuracy: 0.96 - ETA: 2s - loss: 0.1438 - accuracy: 0.96 - ETA: 2s - loss: 0.1457 - accuracy: 0.96 - ETA: 2s - loss: 0.1468 - accuracy: 0.96 - ETA: 2s - loss: 0.1475 - accuracy: 0.96 - ETA: 2s - loss: 0.1459 - accuracy: 0.96 - ETA: 2s - loss: 0.1452 - accuracy: 0.96 - ETA: 2s - loss: 0.1454 - accuracy: 0.96 - ETA: 2s - loss: 0.1450 - accuracy: 0.96 - ETA: 2s - loss: 0.1425 - accuracy: 0.96 - ETA: 2s - loss: 0.1411 - accuracy: 0.96 - ETA: 2s - loss: 0.1408 - accuracy: 0.96 - ETA: 2s - loss: 0.1409 - accuracy: 0.96 - ETA: 2s - loss: 0.1436 - accuracy: 0.96 - ETA: 2s - loss: 0.1430 - accuracy: 0.96 - ETA: 1s - loss: 0.1433 - accuracy: 0.96 - ETA: 1s - loss: 0.1431 - accuracy: 0.96 - ETA: 1s - loss: 0.1421 - accuracy: 0.96 - ETA: 1s - loss: 0.1421 - accuracy: 0.96 - ETA: 1s - loss: 0.1426 - accuracy: 0.96 - ETA: 1s - loss: 0.1416 - accuracy: 0.96 - ETA: 1s - loss: 0.1414 - accuracy: 0.96 - ETA: 1s - loss: 0.1398 - accuracy: 0.96 - ETA: 1s - loss: 0.1385 - accuracy: 0.96 - ETA: 1s - loss: 0.1369 - accuracy: 0.96 - ETA: 1s - loss: 0.1348 - accuracy: 0.96 - ETA: 1s - loss: 0.1365 - accuracy: 0.96 - ETA: 1s - loss: 0.1362 - accuracy: 0.96 - ETA: 1s - loss: 0.1360 - accuracy: 0.96 - ETA: 1s - loss: 0.1356 - accuracy: 0.96 - ETA: 1s - loss: 0.1360 - accuracy: 0.96 - ETA: 1s - loss: 0.1357 - accuracy: 0.96 - ETA: 1s - loss: 0.1353 - accuracy: 0.96 - ETA: 1s - loss: 0.1349 - accuracy: 0.96 - ETA: 0s - loss: 0.1346 - accuracy: 0.96 - ETA: 0s - loss: 0.1338 - accuracy: 0.96 - ETA: 0s - loss: 0.1338 - accuracy: 0.96 - ETA: 0s - loss: 0.1341 - accuracy: 0.96 - ETA: 0s - loss: 0.1350 - accuracy: 0.96 - ETA: 0s - loss: 0.1341 - accuracy: 0.96 - ETA: 0s - loss: 0.1335 - accuracy: 0.96 - ETA: 0s - loss: 0.1344 - accuracy: 0.96 - ETA: 0s - loss: 0.1337 - accuracy: 0.96 - ETA: 0s - loss: 0.1335 - accuracy: 0.96 - ETA: 0s - loss: 0.1325 - accuracy: 0.96 - ETA: 0s - loss: 0.1341 - accuracy: 0.96 - ETA: 0s - loss: 0.1337 - accuracy: 0.96 - ETA: 0s - loss: 0.1328 - accuracy: 0.96 - ETA: 0s - loss: 0.1347 - accuracy: 0.96 - ETA: 0s - loss: 0.1340 - accuracy: 0.96 - ETA: 0s - loss: 0.1361 - accuracy: 0.96 - ETA: 0s - loss: 0.1359 - accuracy: 0.96 - 4s 839us/step - loss: 0.1357 - accuracy: 0.9645 - val_loss: 0.5574 - val_accuracy: 0.7843\n",
      "Epoch 6/10\n",
      "5100/5100 [==============================] - ETA: 3s - loss: 0.0476 - accuracy: 1.00 - ETA: 3s - loss: 0.1158 - accuracy: 0.96 - ETA: 3s - loss: 0.1129 - accuracy: 0.97 - ETA: 3s - loss: 0.1028 - accuracy: 0.97 - ETA: 3s - loss: 0.1074 - accuracy: 0.97 - ETA: 3s - loss: 0.1092 - accuracy: 0.97 - ETA: 3s - loss: 0.1076 - accuracy: 0.97 - ETA: 3s - loss: 0.1085 - accuracy: 0.97 - ETA: 3s - loss: 0.1016 - accuracy: 0.97 - ETA: 3s - loss: 0.1055 - accuracy: 0.97 - ETA: 3s - loss: 0.1060 - accuracy: 0.97 - ETA: 2s - loss: 0.1058 - accuracy: 0.97 - ETA: 2s - loss: 0.1040 - accuracy: 0.97 - ETA: 2s - loss: 0.1004 - accuracy: 0.97 - ETA: 2s - loss: 0.1037 - accuracy: 0.97 - ETA: 2s - loss: 0.1045 - accuracy: 0.97 - ETA: 2s - loss: 0.1034 - accuracy: 0.97 - ETA: 2s - loss: 0.1085 - accuracy: 0.97 - ETA: 2s - loss: 0.1097 - accuracy: 0.97 - ETA: 2s - loss: 0.1096 - accuracy: 0.97 - ETA: 2s - loss: 0.1126 - accuracy: 0.97 - ETA: 2s - loss: 0.1109 - accuracy: 0.97 - ETA: 2s - loss: 0.1153 - accuracy: 0.97 - ETA: 2s - loss: 0.1135 - accuracy: 0.97 - ETA: 2s - loss: 0.1142 - accuracy: 0.97 - ETA: 1s - loss: 0.1163 - accuracy: 0.97 - ETA: 1s - loss: 0.1168 - accuracy: 0.97 - ETA: 1s - loss: 0.1143 - accuracy: 0.97 - ETA: 1s - loss: 0.1166 - accuracy: 0.97 - ETA: 1s - loss: 0.1204 - accuracy: 0.96 - ETA: 1s - loss: 0.1197 - accuracy: 0.96 - ETA: 1s - loss: 0.1184 - accuracy: 0.96 - ETA: 1s - loss: 0.1169 - accuracy: 0.96 - ETA: 1s - loss: 0.1182 - accuracy: 0.96 - ETA: 1s - loss: 0.1172 - accuracy: 0.96 - ETA: 1s - loss: 0.1164 - accuracy: 0.96 - ETA: 1s - loss: 0.1154 - accuracy: 0.96 - ETA: 1s - loss: 0.1147 - accuracy: 0.96 - ETA: 1s - loss: 0.1154 - accuracy: 0.96 - ETA: 0s - loss: 0.1144 - accuracy: 0.96 - ETA: 0s - loss: 0.1153 - accuracy: 0.96 - ETA: 0s - loss: 0.1161 - accuracy: 0.96 - ETA: 0s - loss: 0.1162 - accuracy: 0.96 - ETA: 0s - loss: 0.1158 - accuracy: 0.96 - ETA: 0s - loss: 0.1148 - accuracy: 0.96 - ETA: 0s - loss: 0.1143 - accuracy: 0.96 - ETA: 0s - loss: 0.1151 - accuracy: 0.96 - ETA: 0s - loss: 0.1150 - accuracy: 0.96 - ETA: 0s - loss: 0.1144 - accuracy: 0.96 - ETA: 0s - loss: 0.1141 - accuracy: 0.97 - ETA: 0s - loss: 0.1135 - accuracy: 0.97 - ETA: 0s - loss: 0.1124 - accuracy: 0.97 - ETA: 0s - loss: 0.1121 - accuracy: 0.97 - ETA: 0s - loss: 0.1109 - accuracy: 0.97 - 4s 767us/step - loss: 0.1113 - accuracy: 0.9706 - val_loss: 0.5997 - val_accuracy: 0.7899\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5100/5100 [==============================] - ETA: 4s - loss: 0.0701 - accuracy: 0.96 - ETA: 3s - loss: 0.0577 - accuracy: 0.98 - ETA: 3s - loss: 0.0730 - accuracy: 0.98 - ETA: 3s - loss: 0.0635 - accuracy: 0.98 - ETA: 3s - loss: 0.0730 - accuracy: 0.98 - ETA: 3s - loss: 0.0700 - accuracy: 0.98 - ETA: 3s - loss: 0.0674 - accuracy: 0.98 - ETA: 3s - loss: 0.0675 - accuracy: 0.98 - ETA: 3s - loss: 0.0692 - accuracy: 0.98 - ETA: 3s - loss: 0.0659 - accuracy: 0.98 - ETA: 3s - loss: 0.0705 - accuracy: 0.98 - ETA: 2s - loss: 0.0686 - accuracy: 0.98 - ETA: 2s - loss: 0.0711 - accuracy: 0.98 - ETA: 2s - loss: 0.0683 - accuracy: 0.98 - ETA: 2s - loss: 0.0678 - accuracy: 0.98 - ETA: 2s - loss: 0.0712 - accuracy: 0.98 - ETA: 2s - loss: 0.0758 - accuracy: 0.98 - ETA: 2s - loss: 0.0773 - accuracy: 0.98 - ETA: 2s - loss: 0.0813 - accuracy: 0.98 - ETA: 2s - loss: 0.0818 - accuracy: 0.98 - ETA: 2s - loss: 0.0826 - accuracy: 0.98 - ETA: 2s - loss: 0.0827 - accuracy: 0.98 - ETA: 2s - loss: 0.0848 - accuracy: 0.98 - ETA: 2s - loss: 0.0843 - accuracy: 0.98 - ETA: 2s - loss: 0.0843 - accuracy: 0.98 - ETA: 1s - loss: 0.0833 - accuracy: 0.98 - ETA: 1s - loss: 0.0834 - accuracy: 0.98 - ETA: 1s - loss: 0.0846 - accuracy: 0.98 - ETA: 1s - loss: 0.0843 - accuracy: 0.98 - ETA: 1s - loss: 0.0868 - accuracy: 0.97 - ETA: 1s - loss: 0.0867 - accuracy: 0.97 - ETA: 1s - loss: 0.0902 - accuracy: 0.97 - ETA: 1s - loss: 0.0937 - accuracy: 0.97 - ETA: 1s - loss: 0.0937 - accuracy: 0.97 - ETA: 1s - loss: 0.0951 - accuracy: 0.97 - ETA: 1s - loss: 0.0975 - accuracy: 0.97 - ETA: 1s - loss: 0.0958 - accuracy: 0.97 - ETA: 1s - loss: 0.0960 - accuracy: 0.97 - ETA: 1s - loss: 0.0953 - accuracy: 0.97 - ETA: 1s - loss: 0.0947 - accuracy: 0.97 - ETA: 0s - loss: 0.0944 - accuracy: 0.97 - ETA: 0s - loss: 0.0946 - accuracy: 0.97 - ETA: 0s - loss: 0.0956 - accuracy: 0.97 - ETA: 0s - loss: 0.0947 - accuracy: 0.97 - ETA: 0s - loss: 0.0959 - accuracy: 0.97 - ETA: 0s - loss: 0.0967 - accuracy: 0.97 - ETA: 0s - loss: 0.0978 - accuracy: 0.97 - ETA: 0s - loss: 0.0979 - accuracy: 0.97 - ETA: 0s - loss: 0.0983 - accuracy: 0.97 - ETA: 0s - loss: 0.0971 - accuracy: 0.97 - ETA: 0s - loss: 0.0968 - accuracy: 0.97 - ETA: 0s - loss: 0.0961 - accuracy: 0.97 - ETA: 0s - loss: 0.0962 - accuracy: 0.97 - ETA: 0s - loss: 0.0970 - accuracy: 0.97 - 4s 761us/step - loss: 0.0968 - accuracy: 0.9749 - val_loss: 0.6349 - val_accuracy: 0.7959\n",
      "Epoch 8/10\n",
      "5100/5100 [==============================] - ETA: 3s - loss: 0.0367 - accuracy: 1.00 - ETA: 3s - loss: 0.0340 - accuracy: 1.00 - ETA: 3s - loss: 0.0384 - accuracy: 0.99 - ETA: 3s - loss: 0.0445 - accuracy: 0.99 - ETA: 3s - loss: 0.0516 - accuracy: 0.99 - ETA: 3s - loss: 0.0611 - accuracy: 0.98 - ETA: 3s - loss: 0.0595 - accuracy: 0.98 - ETA: 3s - loss: 0.0635 - accuracy: 0.98 - ETA: 3s - loss: 0.0631 - accuracy: 0.98 - ETA: 2s - loss: 0.0768 - accuracy: 0.98 - ETA: 2s - loss: 0.0785 - accuracy: 0.98 - ETA: 2s - loss: 0.0746 - accuracy: 0.98 - ETA: 2s - loss: 0.0781 - accuracy: 0.98 - ETA: 2s - loss: 0.0801 - accuracy: 0.98 - ETA: 2s - loss: 0.0818 - accuracy: 0.97 - ETA: 2s - loss: 0.0800 - accuracy: 0.97 - ETA: 2s - loss: 0.0825 - accuracy: 0.97 - ETA: 2s - loss: 0.0822 - accuracy: 0.97 - ETA: 2s - loss: 0.0865 - accuracy: 0.97 - ETA: 2s - loss: 0.0847 - accuracy: 0.97 - ETA: 2s - loss: 0.0833 - accuracy: 0.97 - ETA: 2s - loss: 0.0869 - accuracy: 0.97 - ETA: 2s - loss: 0.0853 - accuracy: 0.97 - ETA: 2s - loss: 0.0855 - accuracy: 0.97 - ETA: 1s - loss: 0.0861 - accuracy: 0.97 - ETA: 1s - loss: 0.0849 - accuracy: 0.97 - ETA: 1s - loss: 0.0846 - accuracy: 0.97 - ETA: 1s - loss: 0.0845 - accuracy: 0.97 - ETA: 1s - loss: 0.0833 - accuracy: 0.97 - ETA: 1s - loss: 0.0829 - accuracy: 0.97 - ETA: 1s - loss: 0.0843 - accuracy: 0.97 - ETA: 1s - loss: 0.0845 - accuracy: 0.97 - ETA: 1s - loss: 0.0851 - accuracy: 0.97 - ETA: 1s - loss: 0.0843 - accuracy: 0.97 - ETA: 1s - loss: 0.0848 - accuracy: 0.97 - ETA: 1s - loss: 0.0874 - accuracy: 0.97 - ETA: 1s - loss: 0.0878 - accuracy: 0.97 - ETA: 1s - loss: 0.0878 - accuracy: 0.97 - ETA: 1s - loss: 0.0878 - accuracy: 0.97 - ETA: 1s - loss: 0.0868 - accuracy: 0.97 - ETA: 0s - loss: 0.0858 - accuracy: 0.97 - ETA: 0s - loss: 0.0861 - accuracy: 0.97 - ETA: 0s - loss: 0.0857 - accuracy: 0.97 - ETA: 0s - loss: 0.0852 - accuracy: 0.97 - ETA: 0s - loss: 0.0862 - accuracy: 0.97 - ETA: 0s - loss: 0.0857 - accuracy: 0.97 - ETA: 0s - loss: 0.0851 - accuracy: 0.97 - ETA: 0s - loss: 0.0847 - accuracy: 0.97 - ETA: 0s - loss: 0.0864 - accuracy: 0.97 - ETA: 0s - loss: 0.0854 - accuracy: 0.97 - ETA: 0s - loss: 0.0851 - accuracy: 0.97 - ETA: 0s - loss: 0.0853 - accuracy: 0.97 - ETA: 0s - loss: 0.0850 - accuracy: 0.97 - ETA: 0s - loss: 0.0845 - accuracy: 0.97 - 4s 760us/step - loss: 0.0844 - accuracy: 0.9765 - val_loss: 0.6369 - val_accuracy: 0.7712\n",
      "Epoch 9/10\n",
      "5100/5100 [==============================] - ETA: 4s - loss: 0.0799 - accuracy: 1.00 - ETA: 3s - loss: 0.0736 - accuracy: 0.98 - ETA: 3s - loss: 0.0806 - accuracy: 0.98 - ETA: 3s - loss: 0.0677 - accuracy: 0.98 - ETA: 3s - loss: 0.0722 - accuracy: 0.98 - ETA: 3s - loss: 0.0735 - accuracy: 0.98 - ETA: 3s - loss: 0.0771 - accuracy: 0.98 - ETA: 3s - loss: 0.0727 - accuracy: 0.98 - ETA: 3s - loss: 0.0790 - accuracy: 0.98 - ETA: 3s - loss: 0.0740 - accuracy: 0.98 - ETA: 2s - loss: 0.0729 - accuracy: 0.98 - ETA: 2s - loss: 0.0734 - accuracy: 0.98 - ETA: 2s - loss: 0.0715 - accuracy: 0.98 - ETA: 2s - loss: 0.0722 - accuracy: 0.98 - ETA: 2s - loss: 0.0706 - accuracy: 0.98 - ETA: 2s - loss: 0.0699 - accuracy: 0.98 - ETA: 2s - loss: 0.0670 - accuracy: 0.98 - ETA: 2s - loss: 0.0658 - accuracy: 0.98 - ETA: 2s - loss: 0.0679 - accuracy: 0.98 - ETA: 2s - loss: 0.0671 - accuracy: 0.98 - ETA: 2s - loss: 0.0660 - accuracy: 0.98 - ETA: 2s - loss: 0.0665 - accuracy: 0.98 - ETA: 2s - loss: 0.0675 - accuracy: 0.98 - ETA: 2s - loss: 0.0702 - accuracy: 0.98 - ETA: 2s - loss: 0.0699 - accuracy: 0.98 - ETA: 1s - loss: 0.0723 - accuracy: 0.97 - ETA: 1s - loss: 0.0713 - accuracy: 0.98 - ETA: 1s - loss: 0.0724 - accuracy: 0.98 - ETA: 1s - loss: 0.0734 - accuracy: 0.98 - ETA: 1s - loss: 0.0749 - accuracy: 0.98 - ETA: 1s - loss: 0.0751 - accuracy: 0.98 - ETA: 1s - loss: 0.0754 - accuracy: 0.98 - ETA: 1s - loss: 0.0743 - accuracy: 0.98 - ETA: 1s - loss: 0.0728 - accuracy: 0.98 - ETA: 1s - loss: 0.0729 - accuracy: 0.98 - ETA: 1s - loss: 0.0720 - accuracy: 0.98 - ETA: 1s - loss: 0.0714 - accuracy: 0.98 - ETA: 1s - loss: 0.0725 - accuracy: 0.98 - ETA: 1s - loss: 0.0729 - accuracy: 0.98 - ETA: 1s - loss: 0.0717 - accuracy: 0.98 - ETA: 0s - loss: 0.0725 - accuracy: 0.98 - ETA: 0s - loss: 0.0723 - accuracy: 0.98 - ETA: 0s - loss: 0.0714 - accuracy: 0.98 - ETA: 0s - loss: 0.0720 - accuracy: 0.98 - ETA: 0s - loss: 0.0723 - accuracy: 0.98 - ETA: 0s - loss: 0.0721 - accuracy: 0.98 - ETA: 0s - loss: 0.0721 - accuracy: 0.98 - ETA: 0s - loss: 0.0720 - accuracy: 0.98 - ETA: 0s - loss: 0.0719 - accuracy: 0.98 - ETA: 0s - loss: 0.0715 - accuracy: 0.98 - ETA: 0s - loss: 0.0721 - accuracy: 0.98 - ETA: 0s - loss: 0.0721 - accuracy: 0.98 - ETA: 0s - loss: 0.0726 - accuracy: 0.98 - ETA: 0s - loss: 0.0727 - accuracy: 0.98 - ETA: 0s - loss: 0.0734 - accuracy: 0.97 - ETA: 0s - loss: 0.0732 - accuracy: 0.97 - 4s 774us/step - loss: 0.0737 - accuracy: 0.9794 - val_loss: 0.6520 - val_accuracy: 0.7907\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5100/5100 [==============================] - ETA: 4s - loss: 0.0233 - accuracy: 1.00 - ETA: 4s - loss: 0.0694 - accuracy: 0.96 - ETA: 3s - loss: 0.0508 - accuracy: 0.97 - ETA: 3s - loss: 0.0560 - accuracy: 0.98 - ETA: 3s - loss: 0.0534 - accuracy: 0.98 - ETA: 3s - loss: 0.0582 - accuracy: 0.98 - ETA: 3s - loss: 0.0553 - accuracy: 0.98 - ETA: 3s - loss: 0.0569 - accuracy: 0.98 - ETA: 3s - loss: 0.0662 - accuracy: 0.97 - ETA: 3s - loss: 0.0627 - accuracy: 0.98 - ETA: 3s - loss: 0.0594 - accuracy: 0.98 - ETA: 2s - loss: 0.0614 - accuracy: 0.98 - ETA: 2s - loss: 0.0622 - accuracy: 0.98 - ETA: 2s - loss: 0.0633 - accuracy: 0.98 - ETA: 2s - loss: 0.0694 - accuracy: 0.98 - ETA: 2s - loss: 0.0670 - accuracy: 0.98 - ETA: 2s - loss: 0.0667 - accuracy: 0.98 - ETA: 2s - loss: 0.0651 - accuracy: 0.98 - ETA: 2s - loss: 0.0633 - accuracy: 0.98 - ETA: 2s - loss: 0.0669 - accuracy: 0.98 - ETA: 2s - loss: 0.0671 - accuracy: 0.98 - ETA: 2s - loss: 0.0670 - accuracy: 0.98 - ETA: 2s - loss: 0.0663 - accuracy: 0.98 - ETA: 2s - loss: 0.0667 - accuracy: 0.98 - ETA: 2s - loss: 0.0675 - accuracy: 0.98 - ETA: 2s - loss: 0.0665 - accuracy: 0.98 - ETA: 2s - loss: 0.0659 - accuracy: 0.98 - ETA: 2s - loss: 0.0658 - accuracy: 0.98 - ETA: 2s - loss: 0.0681 - accuracy: 0.98 - ETA: 2s - loss: 0.0666 - accuracy: 0.98 - ETA: 2s - loss: 0.0660 - accuracy: 0.98 - ETA: 2s - loss: 0.0656 - accuracy: 0.98 - ETA: 2s - loss: 0.0676 - accuracy: 0.98 - ETA: 2s - loss: 0.0666 - accuracy: 0.98 - ETA: 2s - loss: 0.0666 - accuracy: 0.98 - ETA: 2s - loss: 0.0658 - accuracy: 0.98 - ETA: 2s - loss: 0.0647 - accuracy: 0.98 - ETA: 1s - loss: 0.0637 - accuracy: 0.98 - ETA: 1s - loss: 0.0643 - accuracy: 0.98 - ETA: 1s - loss: 0.0640 - accuracy: 0.98 - ETA: 1s - loss: 0.0641 - accuracy: 0.98 - ETA: 1s - loss: 0.0644 - accuracy: 0.98 - ETA: 1s - loss: 0.0636 - accuracy: 0.98 - ETA: 1s - loss: 0.0629 - accuracy: 0.98 - ETA: 1s - loss: 0.0626 - accuracy: 0.98 - ETA: 1s - loss: 0.0629 - accuracy: 0.98 - ETA: 1s - loss: 0.0638 - accuracy: 0.98 - ETA: 1s - loss: 0.0652 - accuracy: 0.98 - ETA: 1s - loss: 0.0650 - accuracy: 0.98 - ETA: 1s - loss: 0.0669 - accuracy: 0.98 - ETA: 1s - loss: 0.0662 - accuracy: 0.98 - ETA: 1s - loss: 0.0669 - accuracy: 0.98 - ETA: 1s - loss: 0.0662 - accuracy: 0.98 - ETA: 1s - loss: 0.0675 - accuracy: 0.98 - ETA: 1s - loss: 0.0667 - accuracy: 0.98 - ETA: 1s - loss: 0.0673 - accuracy: 0.98 - ETA: 0s - loss: 0.0671 - accuracy: 0.98 - ETA: 0s - loss: 0.0677 - accuracy: 0.98 - ETA: 0s - loss: 0.0671 - accuracy: 0.98 - ETA: 0s - loss: 0.0668 - accuracy: 0.98 - ETA: 0s - loss: 0.0665 - accuracy: 0.98 - ETA: 0s - loss: 0.0660 - accuracy: 0.98 - ETA: 0s - loss: 0.0670 - accuracy: 0.98 - ETA: 0s - loss: 0.0669 - accuracy: 0.98 - ETA: 0s - loss: 0.0674 - accuracy: 0.98 - ETA: 0s - loss: 0.0670 - accuracy: 0.98 - ETA: 0s - loss: 0.0672 - accuracy: 0.98 - ETA: 0s - loss: 0.0670 - accuracy: 0.98 - ETA: 0s - loss: 0.0673 - accuracy: 0.98 - ETA: 0s - loss: 0.0673 - accuracy: 0.98 - ETA: 0s - loss: 0.0675 - accuracy: 0.98 - ETA: 0s - loss: 0.0674 - accuracy: 0.98 - ETA: 0s - loss: 0.0676 - accuracy: 0.98 - ETA: 0s - loss: 0.0672 - accuracy: 0.98 - 5s 911us/step - loss: 0.0678 - accuracy: 0.9812 - val_loss: 0.6676 - val_accuracy: 0.7875\n"
     ]
    }
   ],
   "source": [
    "r = model.fit(X_train_data,y_train,epochs=10,verbose=1,\n",
    "         validation_data=(X_val_data,y_val),\n",
    "         callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2007f56ec08>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(r.history['accuracy'],label = 'Training_Accuracy')\n",
    "plt.plot(r.history['val_accuracy'],label = 'val_Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(output_dir+\"/weights.02.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-d06dd87fa1af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_hat_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Model' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "y_hat_classes = model.predict_classes(X_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_y_hat = []\n",
    "for y in y_hat:\n",
    "    float_y_hat.append(y[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydf = pd.DataFrame(list(zip(float_y_hat,y_val)),columns=['y_hat','y_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat</th>\n",
       "      <th>y_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.088783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.089572</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.534186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.068555</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.474488</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2508</td>\n",
       "      <td>0.370149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2509</td>\n",
       "      <td>0.136572</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2510</td>\n",
       "      <td>0.830426</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2511</td>\n",
       "      <td>0.522149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2512</td>\n",
       "      <td>0.194001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2513 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         y_hat  y_val\n",
       "0     0.088783      1\n",
       "1     0.089572      0\n",
       "2     0.534186      1\n",
       "3     0.068555      0\n",
       "4     0.474488      0\n",
       "...        ...    ...\n",
       "2508  0.370149      0\n",
       "2509  0.136572      1\n",
       "2510  0.830426      1\n",
       "2511  0.522149      1\n",
       "2512  0.194001      0\n",
       "\n",
       "[2513 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
