{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,Dropout,Input,Conv1D\n",
    "from keras.layers import Embedding,LSTM,GlobalMaxPooling1D,MaxPooling1D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "twit = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "twit_df = twit.drop(columns = ['id','keyword','location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1             Forest fire near La Ronge Sask. Canada       1\n",
       "2  All residents asked to 'shelter in place' are ...       1\n",
       "3  13,000 people receive #wildfires evacuation or...       1\n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(twit_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326\n"
     ]
    }
   ],
   "source": [
    "print(len(nlp.Defaults.stop_words))\n",
    "stopwords = (nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S\\s+')\n",
    "    return url.sub(r'',text)\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text) # no emoji\n",
    "\n",
    "def remove_punct(text):\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    return text\n",
    "    \n",
    "def stop_words(text):\n",
    "    text = \" \".join(word for word in text.split() if word not in stopwords)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                deeds reason earthquake allah forgive\n",
       "1                forest fire near la ronge sask canada\n",
       "2    residents asked shelter place notified officer...\n",
       "3    people receive wildfires evacuation orders cal...\n",
       "4    got sent photo ruby alaska smoke wildfires pou...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twit_df['text'] = twit_df['text'].apply(remove_URL)\n",
    "twit_df['text'] = twit_df['text'].apply(remove_emoji)\n",
    "twit_df['text'] = twit_df['text'].map(lambda x: remove_punct(x))\n",
    "twit_df['text'] = twit_df['text'].map(lambda x: x.lower())\n",
    "twit_df['text'] = twit_df['text'].apply(stop_words)\n",
    "\n",
    "twit_df['text'][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = twit_df['text']\n",
    "y = twit_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size = 0.33,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5836        photo postapocalypticflimflam prodding rubble\n",
      "30                                                    end\n",
      "1879                   man crush everyday cristianinspire\n",
      "6852    ptsdchat yes feel root shame found rubble trau...\n",
      "2673    autoames hoped join isis ventilated marines tr...\n",
      "Name: text, dtype: object\n",
      "(5100,)\n",
      "\n",
      "\n",
      "\n",
      "5836    0\n",
      "30      0\n",
      "1879    0\n",
      "6852    1\n",
      "2673    0\n",
      "Name: target, dtype: int64\n",
      "\n",
      "\n",
      "\n",
      "2644            new weapon cause unimaginable destruction\n",
      "2227    famping things gishwhes got soaked deluge goin...\n",
      "5448    dt georgegalloway rt gallowaymayor ûïthe col ...\n",
      "132     aftershock school kick great want thank making...\n",
      "6845    response trauma children addicts develop defen...\n",
      "Name: text, dtype: object\n",
      "(2513,)\n",
      "\n",
      "\n",
      "\n",
      "2644    1\n",
      "2227    0\n",
      "5448    1\n",
      "132     0\n",
      "6845    0\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.head())\n",
    "print(X_train.shape)\n",
    "print('\\n\\n')\n",
    "\n",
    "print(y_train.head())\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "print(X_val.head())\n",
    "print(X_val.shape)\n",
    "\n",
    "print('\\n\\n')\n",
    "\n",
    "print(y_val.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 20000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128, 4747, 4748, 503]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13112"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx = tokenizer.word_index\n",
    "\n",
    "print(X_train_seq[0])\n",
    "v= len(word2idx)\n",
    "v\n",
    "#print(X_val_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize input length by padding and trucating\n",
    "\n",
    "X_train_data = pad_sequences(X_train_seq,padding='post')\n",
    "\n",
    "T = X_train_data.shape[1]\n",
    "\n",
    "X_val_data= pad_sequences(X_val_seq,maxlen=T,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2513, 21)\n"
     ]
    }
   ],
   "source": [
    "print(X_val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "D = 20 #embedding dimensionality \n",
    "#M=15  #Hidden state dimensionality\n",
    "\n",
    "\n",
    "i = Input(shape=(T,))\n",
    "x = Embedding(v+1,D)(i)\n",
    "x = Conv1D(32,3,activation='relu')(x)\n",
    "x = MaxPooling1D()(x)\n",
    "x = Conv1D(64,3,activation='relu')(x)\n",
    "x = MaxPooling1D()(x)\n",
    "x = Conv1D(128,3,activation='relu')(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(1,activation = 'sigmoid')(x)\n",
    "\n",
    "model = Model(i,x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 21)                0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 21, 20)            262260    \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 19, 32)            1952      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 9, 32)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 7, 64)             6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 3, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1, 128)            24704     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 295,253\n",
      "Trainable params: 295,253\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'model_output/dense'\n",
    "\n",
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\"/weights.{epoch:02d}.hdf5\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cbatl\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5100 samples, validate on 2513 samples\n",
      "Epoch 1/10\n",
      "5100/5100 [==============================] - ETA: 3:05 - loss: 0.6938 - accuracy: 0.37 - ETA: 31s - loss: 0.6922 - accuracy: 0.5312 - ETA: 17s - loss: 0.6929 - accuracy: 0.517 - ETA: 11s - loss: 0.6918 - accuracy: 0.527 - ETA: 8s - loss: 0.6894 - accuracy: 0.542 - ETA: 7s - loss: 0.6872 - accuracy: 0.55 - ETA: 5s - loss: 0.6826 - accuracy: 0.56 - ETA: 5s - loss: 0.6831 - accuracy: 0.56 - ETA: 4s - loss: 0.6812 - accuracy: 0.56 - ETA: 3s - loss: 0.6817 - accuracy: 0.56 - ETA: 3s - loss: 0.6821 - accuracy: 0.56 - ETA: 3s - loss: 0.6815 - accuracy: 0.55 - ETA: 2s - loss: 0.6809 - accuracy: 0.56 - ETA: 2s - loss: 0.6793 - accuracy: 0.56 - ETA: 2s - loss: 0.6769 - accuracy: 0.57 - ETA: 2s - loss: 0.6744 - accuracy: 0.57 - ETA: 1s - loss: 0.6727 - accuracy: 0.58 - ETA: 1s - loss: 0.6709 - accuracy: 0.59 - ETA: 1s - loss: 0.6664 - accuracy: 0.60 - ETA: 1s - loss: 0.6646 - accuracy: 0.60 - ETA: 1s - loss: 0.6615 - accuracy: 0.60 - ETA: 0s - loss: 0.6578 - accuracy: 0.61 - ETA: 0s - loss: 0.6520 - accuracy: 0.61 - ETA: 0s - loss: 0.6486 - accuracy: 0.62 - ETA: 0s - loss: 0.6453 - accuracy: 0.62 - ETA: 0s - loss: 0.6377 - accuracy: 0.63 - ETA: 0s - loss: 0.6312 - accuracy: 0.63 - ETA: 0s - loss: 0.6266 - accuracy: 0.64 - ETA: 0s - loss: 0.6207 - accuracy: 0.64 - ETA: 0s - loss: 0.6185 - accuracy: 0.64 - 3s 638us/step - loss: 0.6156 - accuracy: 0.6524 - val_loss: 0.4720 - val_accuracy: 0.7799\n",
      "Epoch 2/10\n",
      "5100/5100 [==============================] - ETA: 1s - loss: 0.2811 - accuracy: 0.90 - ETA: 1s - loss: 0.3335 - accuracy: 0.88 - ETA: 1s - loss: 0.3321 - accuracy: 0.87 - ETA: 1s - loss: 0.3202 - accuracy: 0.87 - ETA: 1s - loss: 0.3213 - accuracy: 0.87 - ETA: 1s - loss: 0.3242 - accuracy: 0.87 - ETA: 1s - loss: 0.3271 - accuracy: 0.86 - ETA: 1s - loss: 0.3232 - accuracy: 0.86 - ETA: 1s - loss: 0.3146 - accuracy: 0.86 - ETA: 1s - loss: 0.3107 - accuracy: 0.87 - ETA: 1s - loss: 0.3050 - accuracy: 0.87 - ETA: 1s - loss: 0.3133 - accuracy: 0.87 - ETA: 1s - loss: 0.3135 - accuracy: 0.87 - ETA: 1s - loss: 0.3071 - accuracy: 0.87 - ETA: 0s - loss: 0.3110 - accuracy: 0.87 - ETA: 0s - loss: 0.3116 - accuracy: 0.87 - ETA: 0s - loss: 0.3103 - accuracy: 0.87 - ETA: 0s - loss: 0.3114 - accuracy: 0.87 - ETA: 0s - loss: 0.3134 - accuracy: 0.87 - ETA: 0s - loss: 0.3125 - accuracy: 0.87 - ETA: 0s - loss: 0.3128 - accuracy: 0.87 - ETA: 0s - loss: 0.3132 - accuracy: 0.87 - ETA: 0s - loss: 0.3151 - accuracy: 0.87 - ETA: 0s - loss: 0.3156 - accuracy: 0.87 - ETA: 0s - loss: 0.3139 - accuracy: 0.87 - ETA: 0s - loss: 0.3129 - accuracy: 0.87 - ETA: 0s - loss: 0.3105 - accuracy: 0.87 - ETA: 0s - loss: 0.3110 - accuracy: 0.87 - ETA: 0s - loss: 0.3139 - accuracy: 0.87 - ETA: 0s - loss: 0.3161 - accuracy: 0.87 - ETA: 0s - loss: 0.3162 - accuracy: 0.87 - ETA: 0s - loss: 0.3156 - accuracy: 0.87 - ETA: 0s - loss: 0.3157 - accuracy: 0.87 - 2s 404us/step - loss: 0.3155 - accuracy: 0.8761 - val_loss: 0.4842 - val_accuracy: 0.7855\n",
      "Epoch 3/10\n",
      "5100/5100 [==============================] - ETA: 1s - loss: 0.1219 - accuracy: 0.96 - ETA: 1s - loss: 0.1255 - accuracy: 0.96 - ETA: 1s - loss: 0.1086 - accuracy: 0.97 - ETA: 1s - loss: 0.1154 - accuracy: 0.96 - ETA: 1s - loss: 0.1215 - accuracy: 0.96 - ETA: 1s - loss: 0.1250 - accuracy: 0.95 - ETA: 1s - loss: 0.1201 - accuracy: 0.96 - ETA: 1s - loss: 0.1186 - accuracy: 0.96 - ETA: 1s - loss: 0.1194 - accuracy: 0.96 - ETA: 1s - loss: 0.1187 - accuracy: 0.96 - ETA: 1s - loss: 0.1259 - accuracy: 0.95 - ETA: 1s - loss: 0.1230 - accuracy: 0.95 - ETA: 1s - loss: 0.1234 - accuracy: 0.95 - ETA: 1s - loss: 0.1247 - accuracy: 0.95 - ETA: 0s - loss: 0.1302 - accuracy: 0.95 - ETA: 0s - loss: 0.1255 - accuracy: 0.95 - ETA: 0s - loss: 0.1244 - accuracy: 0.95 - ETA: 0s - loss: 0.1261 - accuracy: 0.95 - ETA: 0s - loss: 0.1264 - accuracy: 0.95 - ETA: 0s - loss: 0.1257 - accuracy: 0.95 - ETA: 0s - loss: 0.1240 - accuracy: 0.95 - ETA: 0s - loss: 0.1292 - accuracy: 0.95 - ETA: 0s - loss: 0.1268 - accuracy: 0.95 - ETA: 0s - loss: 0.1268 - accuracy: 0.95 - ETA: 0s - loss: 0.1255 - accuracy: 0.95 - ETA: 0s - loss: 0.1287 - accuracy: 0.95 - ETA: 0s - loss: 0.1306 - accuracy: 0.95 - ETA: 0s - loss: 0.1317 - accuracy: 0.95 - ETA: 0s - loss: 0.1328 - accuracy: 0.95 - ETA: 0s - loss: 0.1319 - accuracy: 0.95 - ETA: 0s - loss: 0.1314 - accuracy: 0.95 - ETA: 0s - loss: 0.1325 - accuracy: 0.95 - 2s 394us/step - loss: 0.1328 - accuracy: 0.9557 - val_loss: 0.5793 - val_accuracy: 0.7776\n",
      "Epoch 4/10\n",
      "5100/5100 [==============================] - ETA: 0s - loss: 0.0431 - accuracy: 1.00 - ETA: 1s - loss: 0.0840 - accuracy: 0.97 - ETA: 1s - loss: 0.0686 - accuracy: 0.98 - ETA: 1s - loss: 0.0687 - accuracy: 0.98 - ETA: 1s - loss: 0.0712 - accuracy: 0.97 - ETA: 1s - loss: 0.0732 - accuracy: 0.97 - ETA: 1s - loss: 0.0721 - accuracy: 0.97 - ETA: 1s - loss: 0.0671 - accuracy: 0.98 - ETA: 1s - loss: 0.0712 - accuracy: 0.97 - ETA: 1s - loss: 0.0736 - accuracy: 0.97 - ETA: 1s - loss: 0.0715 - accuracy: 0.97 - ETA: 1s - loss: 0.0714 - accuracy: 0.97 - ETA: 1s - loss: 0.0784 - accuracy: 0.97 - ETA: 0s - loss: 0.0799 - accuracy: 0.97 - ETA: 0s - loss: 0.0787 - accuracy: 0.97 - ETA: 0s - loss: 0.0763 - accuracy: 0.97 - ETA: 0s - loss: 0.0754 - accuracy: 0.97 - ETA: 0s - loss: 0.0736 - accuracy: 0.97 - ETA: 0s - loss: 0.0743 - accuracy: 0.97 - ETA: 0s - loss: 0.0721 - accuracy: 0.97 - ETA: 0s - loss: 0.0707 - accuracy: 0.97 - ETA: 0s - loss: 0.0719 - accuracy: 0.97 - ETA: 0s - loss: 0.0728 - accuracy: 0.97 - ETA: 0s - loss: 0.0738 - accuracy: 0.97 - ETA: 0s - loss: 0.0775 - accuracy: 0.97 - ETA: 0s - loss: 0.0761 - accuracy: 0.97 - ETA: 0s - loss: 0.0788 - accuracy: 0.97 - ETA: 0s - loss: 0.0807 - accuracy: 0.97 - ETA: 0s - loss: 0.0817 - accuracy: 0.97 - ETA: 0s - loss: 0.0812 - accuracy: 0.97 - ETA: 0s - loss: 0.0813 - accuracy: 0.97 - ETA: 0s - loss: 0.0820 - accuracy: 0.97 - 2s 395us/step - loss: 0.0814 - accuracy: 0.9743 - val_loss: 0.6605 - val_accuracy: 0.7684\n",
      "Epoch 5/10\n",
      "5100/5100 [==============================] - ETA: 1s - loss: 0.0428 - accuracy: 1.00 - ETA: 1s - loss: 0.0405 - accuracy: 0.98 - ETA: 1s - loss: 0.0414 - accuracy: 0.98 - ETA: 1s - loss: 0.0389 - accuracy: 0.98 - ETA: 1s - loss: 0.0387 - accuracy: 0.98 - ETA: 1s - loss: 0.0409 - accuracy: 0.98 - ETA: 1s - loss: 0.0485 - accuracy: 0.98 - ETA: 1s - loss: 0.0452 - accuracy: 0.98 - ETA: 1s - loss: 0.0430 - accuracy: 0.98 - ETA: 1s - loss: 0.0410 - accuracy: 0.98 - ETA: 1s - loss: 0.0401 - accuracy: 0.98 - ETA: 1s - loss: 0.0415 - accuracy: 0.98 - ETA: 1s - loss: 0.0461 - accuracy: 0.98 - ETA: 0s - loss: 0.0528 - accuracy: 0.98 - ETA: 0s - loss: 0.0545 - accuracy: 0.98 - ETA: 0s - loss: 0.0540 - accuracy: 0.98 - ETA: 0s - loss: 0.0549 - accuracy: 0.98 - ETA: 0s - loss: 0.0550 - accuracy: 0.98 - ETA: 0s - loss: 0.0574 - accuracy: 0.98 - ETA: 0s - loss: 0.0553 - accuracy: 0.98 - ETA: 0s - loss: 0.0566 - accuracy: 0.98 - ETA: 0s - loss: 0.0572 - accuracy: 0.98 - ETA: 0s - loss: 0.0577 - accuracy: 0.98 - ETA: 0s - loss: 0.0583 - accuracy: 0.98 - ETA: 0s - loss: 0.0579 - accuracy: 0.98 - ETA: 0s - loss: 0.0577 - accuracy: 0.98 - ETA: 0s - loss: 0.0585 - accuracy: 0.98 - ETA: 0s - loss: 0.0577 - accuracy: 0.98 - ETA: 0s - loss: 0.0574 - accuracy: 0.98 - ETA: 0s - loss: 0.0581 - accuracy: 0.98 - ETA: 0s - loss: 0.0593 - accuracy: 0.98 - 2s 380us/step - loss: 0.0591 - accuracy: 0.9800 - val_loss: 0.7131 - val_accuracy: 0.7692\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5100/5100 [==============================] - ETA: 1s - loss: 0.0906 - accuracy: 0.96 - ETA: 1s - loss: 0.0363 - accuracy: 0.98 - ETA: 1s - loss: 0.0302 - accuracy: 0.98 - ETA: 1s - loss: 0.0309 - accuracy: 0.98 - ETA: 1s - loss: 0.0393 - accuracy: 0.98 - ETA: 1s - loss: 0.0427 - accuracy: 0.98 - ETA: 1s - loss: 0.0444 - accuracy: 0.98 - ETA: 1s - loss: 0.0416 - accuracy: 0.98 - ETA: 1s - loss: 0.0427 - accuracy: 0.98 - ETA: 1s - loss: 0.0453 - accuracy: 0.98 - ETA: 1s - loss: 0.0440 - accuracy: 0.98 - ETA: 1s - loss: 0.0425 - accuracy: 0.98 - ETA: 0s - loss: 0.0410 - accuracy: 0.98 - ETA: 0s - loss: 0.0425 - accuracy: 0.98 - ETA: 0s - loss: 0.0412 - accuracy: 0.98 - ETA: 0s - loss: 0.0400 - accuracy: 0.98 - ETA: 0s - loss: 0.0380 - accuracy: 0.98 - ETA: 0s - loss: 0.0365 - accuracy: 0.98 - ETA: 0s - loss: 0.0380 - accuracy: 0.98 - ETA: 0s - loss: 0.0398 - accuracy: 0.98 - ETA: 0s - loss: 0.0417 - accuracy: 0.98 - ETA: 0s - loss: 0.0429 - accuracy: 0.98 - ETA: 0s - loss: 0.0424 - accuracy: 0.98 - ETA: 0s - loss: 0.0430 - accuracy: 0.98 - ETA: 0s - loss: 0.0434 - accuracy: 0.98 - ETA: 0s - loss: 0.0438 - accuracy: 0.98 - ETA: 0s - loss: 0.0446 - accuracy: 0.98 - ETA: 0s - loss: 0.0448 - accuracy: 0.98 - ETA: 0s - loss: 0.0464 - accuracy: 0.98 - ETA: 0s - loss: 0.0457 - accuracy: 0.98 - ETA: 0s - loss: 0.0480 - accuracy: 0.98 - ETA: 0s - loss: 0.0474 - accuracy: 0.98 - 2s 393us/step - loss: 0.0472 - accuracy: 0.9825 - val_loss: 0.7742 - val_accuracy: 0.7557\n",
      "Epoch 7/10\n",
      "5100/5100 [==============================] - ETA: 1s - loss: 0.0231 - accuracy: 1.00 - ETA: 1s - loss: 0.0124 - accuracy: 1.00 - ETA: 1s - loss: 0.0188 - accuracy: 0.99 - ETA: 1s - loss: 0.0270 - accuracy: 0.99 - ETA: 1s - loss: 0.0279 - accuracy: 0.98 - ETA: 1s - loss: 0.0249 - accuracy: 0.99 - ETA: 1s - loss: 0.0226 - accuracy: 0.99 - ETA: 1s - loss: 0.0218 - accuracy: 0.99 - ETA: 1s - loss: 0.0201 - accuracy: 0.99 - ETA: 1s - loss: 0.0276 - accuracy: 0.98 - ETA: 1s - loss: 0.0277 - accuracy: 0.98 - ETA: 1s - loss: 0.0388 - accuracy: 0.98 - ETA: 1s - loss: 0.0368 - accuracy: 0.98 - ETA: 1s - loss: 0.0378 - accuracy: 0.98 - ETA: 1s - loss: 0.0377 - accuracy: 0.98 - ETA: 0s - loss: 0.0392 - accuracy: 0.98 - ETA: 0s - loss: 0.0404 - accuracy: 0.98 - ETA: 0s - loss: 0.0430 - accuracy: 0.98 - ETA: 0s - loss: 0.0421 - accuracy: 0.98 - ETA: 0s - loss: 0.0426 - accuracy: 0.98 - ETA: 0s - loss: 0.0434 - accuracy: 0.98 - ETA: 0s - loss: 0.0421 - accuracy: 0.98 - ETA: 0s - loss: 0.0430 - accuracy: 0.98 - ETA: 0s - loss: 0.0453 - accuracy: 0.98 - ETA: 0s - loss: 0.0439 - accuracy: 0.98 - ETA: 0s - loss: 0.0448 - accuracy: 0.98 - ETA: 0s - loss: 0.0435 - accuracy: 0.98 - ETA: 0s - loss: 0.0429 - accuracy: 0.98 - ETA: 0s - loss: 0.0431 - accuracy: 0.98 - ETA: 0s - loss: 0.0433 - accuracy: 0.98 - ETA: 0s - loss: 0.0421 - accuracy: 0.98 - ETA: 0s - loss: 0.0430 - accuracy: 0.98 - ETA: 0s - loss: 0.0431 - accuracy: 0.98 - 2s 421us/step - loss: 0.0433 - accuracy: 0.9831 - val_loss: 0.7662 - val_accuracy: 0.7788\n",
      "Epoch 8/10\n",
      "5100/5100 [==============================] - ETA: 1s - loss: 0.0076 - accuracy: 1.00 - ETA: 1s - loss: 0.0437 - accuracy: 0.97 - ETA: 1s - loss: 0.0276 - accuracy: 0.98 - ETA: 1s - loss: 0.0279 - accuracy: 0.98 - ETA: 1s - loss: 0.0261 - accuracy: 0.98 - ETA: 1s - loss: 0.0253 - accuracy: 0.99 - ETA: 1s - loss: 0.0222 - accuracy: 0.99 - ETA: 1s - loss: 0.0246 - accuracy: 0.99 - ETA: 1s - loss: 0.0221 - accuracy: 0.99 - ETA: 1s - loss: 0.0218 - accuracy: 0.99 - ETA: 1s - loss: 0.0223 - accuracy: 0.99 - ETA: 1s - loss: 0.0250 - accuracy: 0.99 - ETA: 1s - loss: 0.0234 - accuracy: 0.99 - ETA: 1s - loss: 0.0233 - accuracy: 0.99 - ETA: 0s - loss: 0.0254 - accuracy: 0.99 - ETA: 0s - loss: 0.0251 - accuracy: 0.99 - ETA: 0s - loss: 0.0289 - accuracy: 0.98 - ETA: 0s - loss: 0.0273 - accuracy: 0.98 - ETA: 0s - loss: 0.0275 - accuracy: 0.98 - ETA: 0s - loss: 0.0296 - accuracy: 0.98 - ETA: 0s - loss: 0.0340 - accuracy: 0.98 - ETA: 0s - loss: 0.0346 - accuracy: 0.98 - ETA: 0s - loss: 0.0344 - accuracy: 0.98 - ETA: 0s - loss: 0.0350 - accuracy: 0.98 - ETA: 0s - loss: 0.0344 - accuracy: 0.98 - ETA: 0s - loss: 0.0356 - accuracy: 0.98 - ETA: 0s - loss: 0.0367 - accuracy: 0.98 - ETA: 0s - loss: 0.0371 - accuracy: 0.98 - ETA: 0s - loss: 0.0386 - accuracy: 0.98 - ETA: 0s - loss: 0.0380 - accuracy: 0.98 - ETA: 0s - loss: 0.0380 - accuracy: 0.98 - ETA: 0s - loss: 0.0385 - accuracy: 0.98 - 2s 399us/step - loss: 0.0388 - accuracy: 0.9833 - val_loss: 0.7746 - val_accuracy: 0.7752\n",
      "Epoch 9/10\n",
      "5100/5100 [==============================] - ETA: 1s - loss: 0.0033 - accuracy: 1.00 - ETA: 1s - loss: 0.0238 - accuracy: 0.98 - ETA: 1s - loss: 0.0305 - accuracy: 0.98 - ETA: 1s - loss: 0.0333 - accuracy: 0.98 - ETA: 1s - loss: 0.0324 - accuracy: 0.98 - ETA: 1s - loss: 0.0287 - accuracy: 0.98 - ETA: 1s - loss: 0.0251 - accuracy: 0.98 - ETA: 1s - loss: 0.0232 - accuracy: 0.98 - ETA: 1s - loss: 0.0242 - accuracy: 0.98 - ETA: 1s - loss: 0.0298 - accuracy: 0.98 - ETA: 1s - loss: 0.0309 - accuracy: 0.98 - ETA: 1s - loss: 0.0317 - accuracy: 0.98 - ETA: 1s - loss: 0.0310 - accuracy: 0.98 - ETA: 1s - loss: 0.0320 - accuracy: 0.98 - ETA: 0s - loss: 0.0343 - accuracy: 0.98 - ETA: 0s - loss: 0.0331 - accuracy: 0.98 - ETA: 0s - loss: 0.0318 - accuracy: 0.98 - ETA: 0s - loss: 0.0334 - accuracy: 0.98 - ETA: 0s - loss: 0.0331 - accuracy: 0.98 - ETA: 0s - loss: 0.0325 - accuracy: 0.98 - ETA: 0s - loss: 0.0330 - accuracy: 0.98 - ETA: 0s - loss: 0.0335 - accuracy: 0.98 - ETA: 0s - loss: 0.0329 - accuracy: 0.98 - ETA: 0s - loss: 0.0335 - accuracy: 0.98 - ETA: 0s - loss: 0.0333 - accuracy: 0.98 - ETA: 0s - loss: 0.0337 - accuracy: 0.98 - ETA: 0s - loss: 0.0333 - accuracy: 0.98 - ETA: 0s - loss: 0.0338 - accuracy: 0.98 - ETA: 0s - loss: 0.0333 - accuracy: 0.98 - ETA: 0s - loss: 0.0333 - accuracy: 0.98 - ETA: 0s - loss: 0.0342 - accuracy: 0.98 - ETA: 0s - loss: 0.0354 - accuracy: 0.98 - 2s 395us/step - loss: 0.0367 - accuracy: 0.9841 - val_loss: 0.7959 - val_accuracy: 0.7600\n",
      "Epoch 10/10\n",
      "5100/5100 [==============================] - ETA: 1s - loss: 0.0245 - accuracy: 1.00 - ETA: 1s - loss: 0.0169 - accuracy: 0.99 - ETA: 1s - loss: 0.0231 - accuracy: 0.98 - ETA: 1s - loss: 0.0218 - accuracy: 0.98 - ETA: 1s - loss: 0.0316 - accuracy: 0.98 - ETA: 1s - loss: 0.0352 - accuracy: 0.98 - ETA: 1s - loss: 0.0315 - accuracy: 0.98 - ETA: 1s - loss: 0.0294 - accuracy: 0.98 - ETA: 1s - loss: 0.0292 - accuracy: 0.98 - ETA: 1s - loss: 0.0274 - accuracy: 0.98 - ETA: 1s - loss: 0.0281 - accuracy: 0.98 - ETA: 1s - loss: 0.0274 - accuracy: 0.98 - ETA: 1s - loss: 0.0270 - accuracy: 0.98 - ETA: 1s - loss: 0.0265 - accuracy: 0.98 - ETA: 0s - loss: 0.0269 - accuracy: 0.98 - ETA: 0s - loss: 0.0265 - accuracy: 0.98 - ETA: 0s - loss: 0.0260 - accuracy: 0.98 - ETA: 0s - loss: 0.0264 - accuracy: 0.98 - ETA: 0s - loss: 0.0277 - accuracy: 0.98 - ETA: 0s - loss: 0.0276 - accuracy: 0.98 - ETA: 0s - loss: 0.0300 - accuracy: 0.98 - ETA: 0s - loss: 0.0297 - accuracy: 0.98 - ETA: 0s - loss: 0.0300 - accuracy: 0.98 - ETA: 0s - loss: 0.0292 - accuracy: 0.98 - ETA: 0s - loss: 0.0290 - accuracy: 0.98 - ETA: 0s - loss: 0.0294 - accuracy: 0.98 - ETA: 0s - loss: 0.0304 - accuracy: 0.98 - ETA: 0s - loss: 0.0328 - accuracy: 0.98 - ETA: 0s - loss: 0.0329 - accuracy: 0.98 - ETA: 0s - loss: 0.0334 - accuracy: 0.98 - ETA: 0s - loss: 0.0326 - accuracy: 0.98 - ETA: 0s - loss: 0.0322 - accuracy: 0.98 - 2s 400us/step - loss: 0.0331 - accuracy: 0.9857 - val_loss: 0.8261 - val_accuracy: 0.7732\n"
     ]
    }
   ],
   "source": [
    "r = model.fit(X_train_data,y_train,epochs=10,verbose=1,\n",
    "         validation_data=(X_val_data,y_val),\n",
    "         callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b271905dc8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(r.history['accuracy'],label = 'Training_Accuracy')\n",
    "plt.plot(r.history['val_accuracy'],label = 'val_Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(output_dir+\"/weights.09.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_y_hat = []\n",
    "for y in y_hat:\n",
    "    float_y_hat.append(y[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydf = pd.DataFrame(list(zip(float_y_hat,y_val)),columns=['y_hat','y_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
